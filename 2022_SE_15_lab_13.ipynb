{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dqiffHvojzUS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Kmyaa3MTkEnA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define Input and Expected Output"
      ],
      "metadata": {
        "id": "yCkLMY8ykoAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input dataset\n",
        "Y = np.array([0, 1, 1, 1])  # Expected output\n",
        "# Define the OR Gate dataset (Inputs and Outputs)\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "Y = np.array([0, 1, 1, 1])  # Target values\n"
      ],
      "metadata": {
        "id": "fADze0YhkJfr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Initialize Weights and Bias"
      ],
      "metadata": {
        "id": "6w8uY-rEk68g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly initialize the weights and bias\n",
        "weights = np.random.uniform(size=2)  # Two weights for two inputs\n",
        "bias = np.random.uniform()  # Single bias value\n"
      ],
      "metadata": {
        "id": "o1fBrPlClDlv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Define Hyperparameters"
      ],
      "metadata": {
        "id": "UdE7mP2rlIdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set learning parameters\n",
        "LEARNING_RATE = 0.1\n",
        "EPOCHS = 100  # Total training cycles\n"
      ],
      "metadata": {
        "id": "3SlU7DNOlSCY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 5: Define Activation Function"
      ],
      "metadata": {
        "id": "n9qzV-zBlXf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function: Step function\n",
        "def activation(z: float) -> int:\n",
        "    \"\"\"Returns 1 if input is non-negative, else 0\"\"\"\n",
        "    return int(z >= 0)\n"
      ],
      "metadata": {
        "id": "txB6x0QLlqRm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Perceptron Model\n",
        "for epoch in range(EPOCHS):\n",
        "    total_error = 0  # Track total errors in the epoch\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        # Compute weighted sum: z = w1*x1 + w2*x2 + bias\n",
        "        z = np.dot(X[i], weights) + bias\n",
        "        y_pred = activation(z)  # Apply step function\n",
        "\n",
        "        # Calculate the error\n",
        "        error = Y[i] - y_pred\n",
        "        total_error += abs(error)  # Accumulate absolute errors\n",
        "\n",
        "        # Update weights and bias using Perceptron Learning Rule\n",
        "        weights += LEARNING_RATE * error * X[i]\n",
        "        bias += LEARNING_RATE * error\n",
        "\n",
        "    # Early stopping if perfect classification is achieved\n",
        "    if total_error == 0:\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s24bGl8GmjsH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display final weights and bias\n",
        "print(\"Final Weights:\", weights)\n",
        "print(\"Final Bias:\", bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYC2iUoFmt44",
        "outputId": "5b6a756c-b246-47f5-ed15-16637d391991"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.93893746 0.28260842]\n",
            "Final Bias: -0.07499685965155778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the trained Perceptron model\n",
        "print(\"\\nTesting the Perceptron Model:\")\n",
        "for i in range(len(X)):\n",
        "    z = np.dot(X[i], weights) + bias\n",
        "    output = activation(z)\n",
        "    print(f\"Input: {X[i]} => Predicted Output: {output}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTqvrMLjmvDU",
        "outputId": "aab3688c-9e2b-4292-a237-c1d152bc9e3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the Perceptron Model:\n",
            "Input: [0 0] => Predicted Output: 0\n",
            "Input: [0 1] => Predicted Output: 1\n",
            "Input: [1 0] => Predicted Output: 1\n",
            "Input: [1 1] => Predicted Output: 1\n"
          ]
        }
      ]
    }
  ]
}